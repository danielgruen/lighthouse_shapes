% 
% ======================================================================
\RequirePackage{docswitch}
% \flag is set by the user, through the makefile:
%    make note
%    make apj
% etc.
\setjournal{\flag}

\documentclass[\docopts]{\docclass}

% You could also define the document class directly
%\documentclass[]{emulateapj}

% Custom commands from LSST DESC, see texmf/styles/lsstdesc_macros.sty
\usepackage{lsstdesc_macros}
\usepackage{hyperref}
\usepackage{graphicx}
\graphicspath{{./}{./figures/}}
\bibliographystyle{apj}

% Add your own macros here:

\newcommand{\Mcal}{\texttt{Metacalibration}}
\newcommand{\mcal}{\texttt{metacalibration}}
\newcommand{\snr}{S/N}


% 
% ======================================================================

\begin{document}

\title{ Problems and Solutions for LSST Shape Measurement }

\maketitlepre

\begin{abstract}

LSST weak lensing science has unprecedented requirements for the modelling of the LSST point spread function and the accurate measurement of galaxy shapes in the face of blending. In this document, we describe the results of a workshop on these issues held at Point Montara in February 2017. We discuss available solutions for the PSF modelling and shape measurement, lessons learned from their use in the Dark Energy Survey, remaining open issues, and progress and plans towards fixing those. In addition, we lay out a strategy for handling multi-epoch image data in an API useful with present weak lensing image analysis codes and a framework for validating PSF and shape measurement through image simulations.

\end{abstract}

% Keywords are ignored in the LSST DESC Note style:
\dockeys{latex: templates, papers: awesome}

\maketitlepost

% ----------------------------------------------------------------------
% 

\section{Introduction}
\label{sec:intro}

\FIXME{We skip the introduction for now, but keep an introduction to this \LaTeX\xspace class for reference.}

This is a paper and note template for the LSST DESC \citep{Overview,ScienceBook,WhitePaper}.
You can delete all this tutorial text whenever you like.

You can easily switch between various \LaTeX\xspace styles for internal notes and peer reviewed journals.
Documents can be compiled using the provided \code{Makefile}.
The command \code{make} with no arguments compiles \code{main.tex} using the  \code{lsstdescnote.cls} style.
If you want to upgrade your Note into a journal article, just choose a journal name, between \code{make apj} (ApJ preprint format), \code{make apjl} (which uses the \code{emulateapj} style), \code{make prd}, \code{make prl}, and \code{make mnras}.


There are a number of useful \LaTeX\xspace commands predefined in \code{macros.tex}.
Notice that the section labels are prefixed with \code{sec:} to allow the use of the \verb=\secref= command to reference a section (\ie, \secref{intro}).
Figures can be referenced with the \verb=\figref= command, which assumes that the figure label is prefixed with \code{fig:}.
In \figref{example} we show an example figure.
You'll notice that the actual figure file is found in the \code{figures} directory.
However, because we have specified this directory in our \verb=\graphicspath= we do not need to explicitly specify the path to the image.

The \code{macros.tex} package also contains some conventional scientific units like \angstrom, \GeV, \Msun, etc. and some editorial tools for highlighting \FIXME{issues}, \CHECK{text to be checked}, \COMMENT{comments}, and \NEW{new additions}.


Similar to the figure before, here we have included a table of data from \code{tables/table.tex}.
Notice that again we are able to reference \tabref{example} with the \verb=\tabref= command using the \code{tab:} prefix.
Also notice that we haven't needed to specify the full path to the table because in the \code{Makefile} we include \code{./tables} directory in the \code{\$TEXINPUTS} environment variable.

\input{table}

Equations appear as follows, and can be referred to as, for example, \eqnref{example} -- just as for tables, we use the \verb=\eqnref= command using the \code{eqn:} prefix.
\begin{equation}
  \label{eqn:example}
  \langle f(k) \rangle = \frac{ \sum_{t=0}^{N}f(t,k) }{N}
\end{equation}


\figref{example} shows an example figure, referred to with the \verb=\figref= command and the \code{fig:} prefix.

\begin{figure}
\includegraphics[width=0.9\columnwidth]{example.png}
\caption{An example figure: the LSST DESC logo, copied from \code{.logos/desc-logo.png} into \code{figures/example.png}. \label{fig:example}}
\end{figure}

If you are planning on committing your paper to GitHub, it's a good idea to write your tex as one sentence per line.
This allows for an easier \code{diff} of changes.
It also makes sense to think of latex as \emph{code}, and sentences as logical statements, occupying one line each.
Each line must ``compile'' in the mind of the reader.

% ----------------------------------------------------------------------

\section{MEDS: Multi-epoch data structures}

\FIXME{write why we need this: unified API for PSF modelling / shape measurement / photometry codes to access single frame image, weight, astrometry and PSF information}

\subsection{High-order instrumental astrometric distortions in MEDS}

\FIXME{Gary, Troxel, Mike, Erin: describe how this is implemented}

The \textsc{meds} python class would allow for flexibly swapping out the WCS in the input file FITS header by something more elaborate if we have the base class provide access functions for the \texttt{cutout\_row/col} variables (in addition to the Jacobian) \FIXME{(Erin)}. A derived class could then implement these differently, e.g. by evaluating Gary's WCS \FIXME{(Gary)}. Both this and the way shape measurement codes find the matching PSFEx model files could be implemented by an external simple table that maps exposure and CCD IDs to auxiliary filenames.


\subsection{A MEDS-Like API for LSST}

MEDS has been an overwhelmingly successful approach for providing data to multple multi-epoch object characterization algorithms in DES, but it makes some assumptions that will make it impossible to use directly in LSST.  But the MEDS experience is something LSST must learn from -- multi-epoch fitting is a sufficiently complex task that we will not have the luxury of building a throw-away prototype to learn from before we build the final production system for LSST.  From the LSST perspective, MEDS \emph{is} that prototype, and collaboration with DES represents our best opportunity for learning from it in a production environment.

To that end, we have sketched out a design for a set of interfaces that generalize the MEDS approach to meet the needs of LSST.  We're provisionally calling it \texttt{umemofi}: the Unified Multi-Exposure Multi-Object Fitting Interface.  The design sketch can currently be found at \url{https://github.com/TallJimbo/umemofi}.\footnote{None of this is working code yet, and its home may change in the future.}  The goals of the new interface include:
\begin{itemize}
\item We need to separate the programmatic interface to data structures from their serialization and file formats, enabling drivers that repackage information from CCD-level images on the fly and serialize using LSST DM's ``data butler'' abstraction layer.
\item We need to fully define all interfaces and data structures needed for fitting, instead of leaving some of them to be algorithm- or context-dependent.
\item We need to support algorithms that simultaneously fit multiple objects.
\item We need to run multiple algorithms in a single processing run, without duplicate I/O.
\item We need to allow an external workflow system to control the highest levels of parallelization and data flow.
\end{itemize}
It is also a requirement that it be possible to implement at least the current MEDS \emph{fitting} workflow on top of the new interface.  We may or may not be able to implement the current MEDS \emph{generation} workflow exactly using the new interface (but we hope to make it possible to implement something no worse, even if the logic isn't quite the same).

The design centers around the following classes:
\begin{itemize}
\item \texttt{ObjectData} and {{MultiObjectData}} contain the revelent information from one or more (respectively) astronomical objects, independent of any observations they appear in: their location on the sky, and the results of any measurement algorithms that do not generate per-exposure output quantities.
\item \texttt{Model} abstracts the per-object results of running a fitter or other measurement algorithm, including algorithm-independent serialization of those results and rendering them to images for diagnostic purposes and deblending (by subtracting neighbors).
\item \texttt{Observation} holds all information needed to measure a single object on a single exposure, and \texttt{ObservationMeta} provides an interface for backend-implemented lightweight handles that can load this information on-demand.  \texttt{MultiObjectObservation} and \texttt{MultiObjectObservationMeta} generalize these for algorithms that wish to fit objects simultaneously.  These classes also hold \texttt{Model} objects that represent per-exposure results, such as forced photometry.
\item \texttt{ObjectObservationDict} and \texttt{MultiObjectObservationDict} are containers of \texttt{ObservationMeta}, indexed by different combinations of object and exposure IDs.
\end{itemize}
These in turn rely on a number of primitive classes for representing key image processing concepts:
\begin{itemize}
\item images: conceptually a 2-d array with a potentially nonzero origin
\item masks: integer images where each bit is assigned a different meaning
\item \emph{local} coordinate system transformations (which we approximate as locally affine over the scale of an object)
\item \emph{local} point-spread functions (which we approximate as spatially constant over the scale of an object, but potentially a function of wavelength)
\item \emph{local} photometric transmission functions (which we also approximate as spatially constant over the scale of an object, and a function of wavelength).
\end{itemize}
The local approximations are critical here: they let us avoid including the complex spatial variations of these objects in this interface.  These local approximations must be generated from their complete spatially-varying forms by any \texttt{umemofi}backend, but those more complex objects remain completely hidden behind the backend.

\FIXME{Jim: \texttt{Algorithm} and harness interfaces (the end-game for all of this) still need some fleshing out; do that in Python before trying to describe it here.}

We are also working to make this an active collaboration between DES and LSST, and in particular make sure there are no blockers on eventual DES adoption of \texttt{umemofi} as the primary interface for DES multi-epoch measurement (though we do not expect that to happen soon).  While we expect both projects will always utilize different backends, reflecting different pipelines for earlier stages of processing, this should allow them to share the most important algorithmic code.  This is a huge win for LSST (and DES members who are also LSST members), as it would allow DES-developed state-of-the-art model-fitting codes to be run on LSST DM stack outputs.  It will hopefully also be advantageous for DES, as the new interface should make it easier to reconfigure and test algorithms (especially for dealing with blending), and it should consolidate much of the bookkeeping logic currently scattered across algorithms into a common harness.  To encourage that cross-project collaboration, we intend to minimize the dependencies of the \texttt{umemofi} library itself, even if that involves duplicating in it some primitives LSST has already implemented in its own codebase.  But even this can be seen as an opportunity for LSST: a way to get a small amount of important, high-use, stable LSST DM code (largely from \texttt{afw.geom}) into a separate library that will be more Pythonic and easier to install.  Given that these geometry primives would require work (largely to integrate them with LSST's own \texttt{sphgeom} package, as has long been planned) to meet \texttt{umemofi}'s needs, doing this work in a ``spin-off'' package should involve little or no additional effot.

Our first near-term goals is to finish implementing the utility classes that form the core of the interface, at least in Python.  LSST will ultimately want many of these classes to be available in C++, and it may make sense to implement these in C++ initially (especially if this largely transferring code from \texttt{afw} and adapting it slightly).  We expect that DES will only use the Python interfaces for the forseeable future -- while DES codes will of course use C or C++ in inner loops, we are confident the \texttt{umemofi} interfaces will never need to be used in those inner loops (the LSST desire for these utility objects in C++ is about design philosophy, not performance requirements).  At the same time, we hope to start working on a MEDS backend that allows \texttt{Observation} objects to be loaded from DES-generated MEDS files using the \texttt{umemofi} interface.  From there it should be easy to adapt any MEDS-based fitter into an \texttt{umemofi} \texttt{Algorithm}, allowing those codes to be run via \texttt{umemofi} on MEDS files in more flexible ways.  A minimal LSST backend for \texttt{umemofi} with only simple intra-node parallelization and naive I/O should also be relatively easy to develop, which will enable algorithm development work to proceed while a more scaleable production backend is developed.

% ----------------------------------------------------------------------

\section{PIFF: PSFs in the Full FOV}

\FIXME{write an introduction of why we need this: astrometric distortions -> WCS, coherent patterns over full FOV, Zernickes, better interpolation schemes}

\subsection{Gaussian Process Interpolation}

\FIXME{Josh, Gary, Mike, Niall, Pierre-Francois, Ami: describe}

\subsection{Errors on Adaptive Moments}

The wavefront-based PSF performs a $\chi^2$ fit to the adaptive moments of stars.  However, up to now we have not included an error on the adaptive moments in the fit.  We calculated the errors on the adaptive moments, using the following expressions from simple error propagation:
$$  \sigma^2(e_0) = \sum \left\{ \left[ (u-u_0)^2 + (v-v_0)^2  \right] K(u,v) \right\}^2 \sigma_{I}^2(u,v) $$
$$  \sigma^2(e_1) = \sum \left\{ \left[ (u-u_0)^2 - (v-v_0)^2  \right] K(u,v) \right\}^2 \sigma_{I}^2(u,v) $$
$$  \sigma^2(e_2) = \sum \left\{ \left[ (u-u_0)  (v-v_0)  \right] K(u,v) \right\}^2 \sigma_{I}^2(u,v) $$
where $\sigma_{I}(u,v)$ is the shot noise on an individual pixel and $K(u,v)$ is the kernel used by the HSM algorithm. Note that we have not yet included a contribution from the error on the centroids, nor from the (omitted) normalization term. 

To test this calculation, we used an ensemble of simulated stars, constructed with arbitrary aberration, and with shot noise appropriate for different choices of star S/N. For a stellar flux of $10^5$ photo-electrons, we created 5000 noisy stars, calculated their adaptive moments and errors, and plot the pull distribution for $e_0$, $e_1$ and $e_2$ (note that our $e_1$ and $e_2$ are unnormalized) in Figure~\ref{fig:momerror}.  The pull distributions have RMS  somewhat larger than 1., and we find very similar RMS values independent of flux for values from $10^6$ down to $4\times10^3$.  We suspect that the errors are underestimated because we omit the contribution to the error from the uncertainty in the centroids and the normalization.  


\begin{figure}[h]
\includegraphics[width=0.9\columnwidth]{figures/moment-errors-flux1e5.png}
\caption{The pull distributions for $e_0$, $e_1$ and $e_2$ from a sample of simulated stars with $S/N = 316$. The errors are underestimated by a factor which is independent of S/N. \label{fig:momerror}}
\end{figure}

\subsection{Combining PSF Models}

A goal with PIFF is to model the PSF as a combination of the optical and atmospheric PSFs.
Because these two PSFs have significant differences in implementation, they need to be combined together within PIFF.
Chris wrote a new \texttt{PSF} class, \texttt{CompoundPSF}, while at the lighthouse.
This class can take an arbitrary number of PSFs, and fits each piece iteratively.
The final PSF is a convolution of the PSFs.

\section{Shape measurement}

\FIXME{quick intro of lessons learned from DES Y1}

\subsection{BFD on real data}

The BFD approach to galaxy shape measurement, described in \citet{2014MNRAS.438.1880B} and implemented in \citet{2016MNRAS.459.4467B},  uses a collection of moment templates derived from deep data to generate a posterior for galaxy shapes in shallow data.

We have made progress connecting the BFD code to the MEDS format used in DES and LSST.

The two components missing for this were
\begin{itemize}
\item a variant of \texttt{simpleImage} (see \texttt{momentcalc.py} in the BFD repository) that can take multiple postage stamps of the same galaxies with their respective WCS registrations (in the form of the position of a centroid estimated in WCS and transformed to the postage stamp pixel system) and Jacobians, PSF models, and an estimate of the overall centroid in WCS \FIXME{(Katie)}
\item a function that can get these inputs to the new variant of \texttt{simpleImage} from a MEDS file (using the python \texttt{meds} or a derived class) \FIXME{(Daniel)}
\end{itemize}

A git repository was created at \url{https://github.com/danielgruen/bfdmeds} containing code to use the MEDS library to provide the input PSF information needed by BFD, and to wrap the existing MEDS objects with the new astrometric information provided by the improved WCS measurement process and stored in YAML files.  The library was used with DES Y3 meds files to produce the PSF image below.


\begin{figure}[h]
\includegraphics[width=0.9\columnwidth]{figures/psf-example.png}
\caption{A PSF image generated from DES Y3 PSFEx models from the new bfdmeds repository.}
\end{figure}




% ----------------------------------------------------------------------

\section{An image simulation pipeline for PSF and shape measurement validation}

\FIXME{Joe, Mike, Erin, Troxel, Gary, Daniel, Niall, Ami, Katie: describe}

\subsection{Goals}
Goals: Simulation engines primarily for validation. Win some Gin from Catherine Heymans.

The subsections below describe stages of this process and the options or considerations for it.

\subsection{(Statistical) Requirements}

We need to define cosmology-driven requirements for the simulation, as these will set the simulation volume requirements and thus the computing requirements etc.. Particularly important to do this if we e.g. need to find/apply for more computing resources. 

One simple approach to setting requirements is to assume we only need to estimate a mean multiplicative bias, $\left<m_i\right>$ and additive bias, $\left<c_i\right>$ per redshift bin $i$. Then from a simulation with input shear $\gamma_{\mathrm{true}}$, 
\begin{equation}
\left<m_i\right> = \left<\frac{\gamma_{\mathrm{obs}}-\gamma_{\mathrm{true}}}{\gamma_{\mathrm{true}}}\right>,
\end{equation}
where the (possibly weighed) averaging is over all galaxies in redshift bin $i$. It follows that
\begin{equation}
\sigma_m = \frac{\sigma_e}{\gamma_{\mathrm{true}} \sqrt{N_{\mathrm{gal},i}}}
\end{equation}
i.e. for a given $\sigma_m$ one can estimate the required number of simulated galaxies per redshift bin, $N_{\mathrm{gal},i}$.
For postage-stamp style image simulations which provide effective tests of effects like noise bias, galaxy bias and PSF deconvolution, this kind of approach is probably sufficient, and can be used to set the number of postage-stamps required. We believe these types of simulation are still useful as a first test of shear estimation methods, see the \emph{tide-pool} simulation mode below.

When it comes to testing our ability to estimate unbiased shear statistics on real data, there are many more effects to consider. Even if a shape measurement method can succeed on postage-stamp style simulations selection effects, PSF modelling errors and crowding/blending will produce scale dependent biases on shear statistics. For example, excluding blended galaxies produces a bias in the small-scale cosmic shear signal (blended galaxies are more likely to be in high projected galaxy number density, high convergence regions \citep{hartlap2011,maccrann2017}). Meanwhile for tangential shear statistics such as cluster-lensing, source galaxies which are close to the lens centres are likely effected by different noise properties and worse contamination from blending.

A more complete way of setting the requirements on the image simulations is simply to aim to be able to test the recovery of any shear statistic we estimate on the the real survey data, to some fraction of the statistical uncertainty with which we can estimate that statistic on the real survey data. Assuming shot/shape-noise is the dominant source of statistical error, any shear statistic (that is reliably reproduced in the simulation) can be tested at a precision which is a fraction $f$ of the statistical error by producing $N_{\mathrm{sim}}1/f^2$ simulated copies of the real survey data. 

%I've brain-dumped a few thoughts on a couple of different (but certainly related) approaches %we could take to this, (i) how many galaxies/galaxy pairs do we need to test our desired %statistics to a given precision? (ii) How many realisations of our survey do we need test our %desired statistics to a given precision? I think the second approach is probably simpler %because a simulation of our survey will automatically (of course limited by the simulation %realism) have distributions of certain relevant survey properties (e.g. noise, PSF) that match %the real data. 
%
%We want to demonstrate that our shear estimation pipelines can recover unbiased shear-shear %and tangential shear signals to better than $X_i\%$, $Y_i\%$  for in $n_z$ redshift bins, $i$, %for $0<z<z_{\mathrm{max}}$ for some range of scales $\theta_{\mathrm{min}} < \theta < \theta_{\%mathrm{max}}$ (we could also phrase in terms of $l$ and $C_l$. This requires:
%\begin{align}
%\left<(1+m_i)(1+m_j)\right>(\theta) + \left<c_i c_j\right>(\theta)/\left<\gamma \gamma\right>(\%theta) < X\%, \\ 
%\left<n_{\mathrm{lens}}(1+m_i)\right> < Y\%.
%\end{align}
%
%Ignoring the scale dependence, assuming a constant shear, and that we calculate $m$ as
%\begin{equation}
%\left<m_i\right> = \left<\frac{\gamma_{\mathrm{obs}}-\gamma_{\mathrm{true}}}{\gamma_{\mathrm{%true}}}\right>,
%\end{equation}
%where the (possibly weighed) averaging is over all galaxies in redshift bin $i$.
%\begin{equation}
%\sigma_m = \frac{\sigma_e}{\gamma_{\mathrm{true}} \sqrt{N_{\mathrm{gal}}}}
%\end{equation}
%We want e.g. $\sigma_{m_i} < 0.5 X_i\%$, so e.g. for $X_i = 1\%$, $\gamma_{\mathrm{true}}=0.01$%, $\sigma_e = 0.2$, we'd need to simulate $1.6\times10^7$ galaxies per redshift bin.
%
%Are we worried about scale dependence? For shear-shear, we get selection biases due to %blending (blended galaxies are more likely to be in high galaxy number density, high %convergence regions \citep{hartlap2011,maccrann2017}). Spatial correlations in observing %conditions may produce spatial correlations in the shear biases. For tangential shear, %increased crowding closer to clusters/lens galaxies will produce scale dependent shear biases \%citep{melchior2015,simet2015}.
%
%An alternative way to think about the requirements is to first assume that we want to %simulated $N_{\mathrm{sim}}$ copies of our survey ($N_{\mathrm{sim}}$ could, but probably %wouldn't be less than 1). This approach has the advantage that (to the extent that the %simulated survey properties are realistic), the simulated survey properties (e.g. noise, PSF %etc.) will have the same distributions as the data. If we want to know the accuracy to which %our pipeline recovers some statistic  to better than a fraction $f$ of the shape noise errors %on that statistic we have in the real data, then we require $N_{\mathrm{sim}} = 1/f^2$ %realisations of our data. 

We envisage two main modes of the image simulations. 
\begin{enumerate}
\item \emph{Tide-pool} Fast, straight to postage-stamps simulations where different marine organisms (e.g. complex morphology, PSF model errors) are turned on and off. Galaxies written straight to MEDS files, or are generated on-the-fly. No neighbours.
\item \emph{Pacific} Full single-epoch survey images are rendered. Coadd images are produced for detection/deblending. PSF estimation is performed on the SE images. MEDS files produced using SE images and coadd information. Some shortcuts probably needed!
\end{enumerate}

Discussion points:
\begin{itemize}
\item{What should $N_{\mathrm{sim}}$ be? Note that most of the statistics we use are cosmic variance limited on large scales, so beating down the shape noise may not be so relevant. We will know the `cosmic variance' (or rather we'll know the particular realisation of the cosmological signal) in the simulation. Having said that, if they effects we are most worried about (blending etc.) are worst at small scales, then shape noise would be the dominant source of statistical uncertainty.}
\item{How can we reduce $N_{\mathrm{sim}}$? One option would be to boost the shear signal - the stronger the simulated signal, the better fractional precision can be tested. However, concerns exist about higher order shear biases, and breaking the relation between galaxy number density and shear. For postage-stamp styles simulations, presumably we can use ring-test type tricks to reduce shape noise. Is there something similar we can use for the detection simulation e.g. rotate shape noise between realisations?}
\item{What kind of shear fields should we use? If we use something realistic (e.g. from ray-tracing), how do we test that we're recovering it correctly, given that a given method will only use a subset of the galaxies?}
\end{itemize}

Several main initial tasks:
\begin{enumerate}
\item{Finish writing up this plan. Produce  (NM+)}
\item{Design simulation software framework (JZ+)}
\item{Design and implement input galaxy catalog 
$->$ galaxy appearance modules (can start v. simple, and produce multiple of these!)}
\item{Estimate timings + memory usage for simulation steps. Could split this into several tasks e.g. image rendering timing (i.e. mostly GalSim stuff) (Name?), Coadding/Detection (i.e. SWARP + SExtractor) timing (Name?).}
\item{Estimate computing requirements for various simulation modes (this should be straightforward once the previous step is completed).}
\end{enumerate}

\subsection{Required Ingredients}

\subsubsection{Input Catalogues}

Requirement: Galaxy sample with physically sensible clustering, redshift evolution, morphologies, colours, and correlations between the above. Sufficiently complex morphologies to test model bias, and sensible variation in morphology between filters. 

\begin{itemize}
\item Starting from an observed catalog is problematic: measured quantities get noisy at the faint end, we won't get sub-detection objects.
\item Proposal: Start from N-body + galaxy simulation e.g. BCC.
\item Map simulation outputs (e.g. color, size) to image properties in each filter (e.g. bulge/disc, size, amount of star formation knots). Look into Lanusse method.
\item Needs to go to high enough redshift and depth for deep fields (and for sufficient sub-detection objects in wide-field).
\end{itemize}

\subsubsection{Shear Field}

The following options, probably we'll want to do one of the first two for the Pacific simulation. Other options fine for tide-pool simulation. 
\begin{itemize}
\item From saved N-body results (see above)
\item Spatially varying but without evolution within a redshift bin
\item Spatially varying but without redshift evolution
\item Constant
\end{itemize}

\subsubsection{Survey Details}

\begin{itemize}
\item Real data pointings
\item Exposure times - from real survey
\item Noise levels - from real survey
\item Sky background - from real survey
\item Deep data - Same process but with more exposures
\end{itemize}


\subsubsection{True Astrometry}

\begin{itemize}
\item Flat WCS
\item Real image WCS
\item Gary's WCS
\item FITS header WCS
\item One of the above + some error distribution
\end{itemize}

\subsubsection{True PSF}

\begin{itemize}
\item Estimated real ones from Piff
\item Additional complexity, adding variation on smaller scales than 
\item Fixed values
\item Colour-dependence of PSF.
	  Full implementation 100 times slower.
	  Could make it a function of a single colour parameter, linearly interpolated.
	  Effective PSF from real SED? Function of (g-i).
	  Intra-band resolution of PSF.  Do this at n wavelengths.
	  Like using a chunky SED.
\end{itemize}

\subsubsection{Star Catalogue}

\begin{itemize}
\item Gaia?
\item Randomly, function of latitude.
\item SEDs - some in galsim already, need more?
\end{itemize}

\subsubsection{Artifacts}
\begin{itemize}
\item Tape bumps
\item CTI
\item Brighter-fatter
\item Non-linearity
\item Non-convolutional things
\item Image artifacts
\end{itemize}

\subsubsection{Masking}

\begin{itemize}
\item Real
\item Real + artifacts
\end{itemize}

\subsubsection{Single-epoch Rendering}

\begin{itemize}
\item GalSim
\end{itemize}

\subsubsection{Coadding}
\begin{itemize}
\item Run full pipeline - i.e. run swarp
\item Shortcut option: draw coadd directly. What does this miss? What is required to test this?
\end{itemize}

\subsubsection{Detection \& Segmenting}
\begin{itemize}
\item Needed for lists of detected objects and segmentation masks
\item Run full pipeline - SExtractor on coadd
\item Generate object list and seg map from truth catalogs
\end{itemize}

\subsubsection{Estimated PSF}
\begin{itemize}
\item Find starting stars - on coadd using SExtractor? Can we do this without spread-model?
\item Run PIFF
\item Use truth
\end{itemize}

\subsubsection{Estimated astrometry}
\begin{itemize}
\item Cannot re-do the actual astrometry process
\item Use the original FITS ones
\item Use truth + some error term
\end{itemize}

\subsubsection{Photometric Calibration}
\begin{itemize}
\item Could place a small error on the truth - scale objects by some factor.
\end{itemize}

\subsubsection{MEDS}
\begin{itemize}
\item Make a MEDS file and run on it!
\end{itemize}



\section{\Mcal\ Response for Stars}

Testing to see if we can cause positive responses for stars in a simulation.
In some scenarios we see $<R> \sim 0.25$ in real data.

\subsection{Variations in PSF}

Consider the case where the PSF model used is accurate in the mean but 
for an individual galaxy the truth varies significantly.  The response
for stars at high \snr ($> 100$), and using forward modeling, is shown in
figure \ref{fig:Rstarfm}.  The same for adaptive moments, without
PSF correction. The response has mean about 0.1 for forward modeling,
but nearly zero for adaptive moments.  In both cases the distribution
is nearly gaussian, whereas in real data it tends to be highly asymmetric,
with mode at $R \sim 0.5$.


\begin{figure}[p]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/test_psf_var-000-R11.pdf}

    \caption{Response for high \snr\ stars when varying the PSF from
    object to object, but using
    the mean model when performing \mcal\ operatioins, using the forward modeling estimator.
    Parameters of the best fit gaussian are shown. }

	\label{fig:Rstarfm}

\end{figure}
\begin{figure}[p]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/test_psf_var-000-R11-admom.pdf}

    \caption{Same as figure \ref{fig:Rstarfm}, but adaptive moments estimator with no PSF correction}

	\label{fig:Rstaram}

\end{figure}



% ----------------------------------------------------------------------

\subsection*{Acknowledgments}

We acknowledge financial and organizational support for our workshop from LSSTC and KIPAC and the hospitality of Hostelling International.

\input{acknowledgments}

%{\it Facilities:} \facility{LSST}

% Include both collaboration papers and external citations:
\bibliography{lsstdesc,main}

\end{document}
% ======================================================================
% 

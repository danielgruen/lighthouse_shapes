% 
% ======================================================================
\RequirePackage{docswitch}
% \flag is set by the user, through the makefile:
%    make note
%    make apj
% etc.
\setjournal{\flag}

\documentclass[\docopts]{\docclass}

% You could also define the document class directly
%\documentclass[]{emulateapj}

% Custom commands from LSST DESC, see texmf/styles/lsstdesc_macros.sty
\usepackage{lsstdesc_macros}

\usepackage{graphicx}
\graphicspath{{./}{./figures/}}
\bibliographystyle{apj}

% Add your own macros here:

\newcommand{\Mcal}{\texttt{Metacalibration}}
\newcommand{\mcal}{\texttt{metacalibration}}
\newcommand{\snr}{S/N}


% 
% ======================================================================

\begin{document}

\title{ Problems and Solutions for LSST Shape Measurement }

\maketitlepre

\begin{abstract}

LSST weak lensing science has unprecedented requirements for the modelling of the LSST point spread function and the accurate measurement of galaxy shapes in the face of blending. In this document, we describe the results of a workshop on these issues held at Point Montara in February 2017. We discuss available solutions for the PSF modelling and shape measurement, lessons learned from their use in the Dark Energy Survey, remaining open issues, and progress and plans towards fixing those. In addition, we lay out a strategy for handling multi-epoch image data in an API useful with present weak lensing image analysis codes and a framework for validating PSF and shape measurement through image simulations.

\end{abstract}

% Keywords are ignored in the LSST DESC Note style:
\dockeys{latex: templates, papers: awesome}

\maketitlepost

% ----------------------------------------------------------------------
% 

\section{Introduction}
\label{sec:intro}

\FIXME{We skip the introduction for now, but keep an introduction to this \LaTeX\xspace class for reference.}

This is a paper and note template for the LSST DESC \citep{Overview,ScienceBook,WhitePaper}.
You can delete all this tutorial text whenever you like.

You can easily switch between various \LaTeX\xspace styles for internal notes and peer reviewed journals.
Documents can be compiled using the provided \code{Makefile}.
The command \code{make} with no arguments compiles \code{main.tex} using the  \code{lsstdescnote.cls} style.
If you want to upgrade your Note into a journal article, just choose a journal name, between \code{make apj} (ApJ preprint format), \code{make apjl} (which uses the \code{emulateapj} style), \code{make prd}, \code{make prl}, and \code{make mnras}.


There are a number of useful \LaTeX\xspace commands predefined in \code{macros.tex}.
Notice that the section labels are prefixed with \code{sec:} to allow the use of the \verb=\secref= command to reference a section (\ie, \secref{intro}).
Figures can be referenced with the \verb=\figref= command, which assumes that the figure label is prefixed with \code{fig:}.
In \figref{example} we show an example figure.
You'll notice that the actual figure file is found in the \code{figures} directory.
However, because we have specified this directory in our \verb=\graphicspath= we do not need to explicitly specify the path to the image.

The \code{macros.tex} package also contains some conventional scientific units like \angstrom, \GeV, \Msun, etc. and some editorial tools for highlighting \FIXME{issues}, \CHECK{text to be checked}, \COMMENT{comments}, and \NEW{new additions}.


Similar to the figure before, here we have included a table of data from \code{tables/table.tex}.
Notice that again we are able to reference \tabref{example} with the \verb=\tabref= command using the \code{tab:} prefix.
Also notice that we haven't needed to specify the full path to the table because in the \code{Makefile} we include \code{./tables} directory in the \code{\$TEXINPUTS} environment variable.

\input{table}

Equations appear as follows, and can be referred to as, for example, \eqnref{example} -- just as for tables, we use the \verb=\eqnref= command using the \code{eqn:} prefix.
\begin{equation}
  \label{eqn:example}
  \langle f(k) \rangle = \frac{ \sum_{t=0}^{N}f(t,k) }{N}
\end{equation}


\figref{example} shows an example figure, referred to with the \verb=\figref= command and the \code{fig:} prefix.

\begin{figure}
\includegraphics[width=0.9\columnwidth]{example.png}
\caption{An example figure: the LSST DESC logo, copied from \code{.logos/desc-logo.png} into \code{figures/example.png}. \label{fig:example}}
\end{figure}

If you are planning on committing your paper to GitHub, it's a good idea to write your tex as one sentence per line.
This allows for an easier \code{diff} of changes.
It also makes sense to think of latex as \emph{code}, and sentences as logical statements, occupying one line each.
Each line must ``compile'' in the mind of the reader.

% ----------------------------------------------------------------------

\section{MEDS: Multi-epoch data structures}

\FIXME{write why we need this: unified API for PSF modelling / shape measurement / photometry codes to access single frame image, weight, astrometry and PSF information}

\subsection{High-order instrumental astrometric distortions in MEDS}

\FIXME{Gary, Troxel, Mike, Erin: describe how this is implemented}

The \textsc{meds} python class would allow for flexibly swapping out the WCS in the input file FITS header by something more elaborate if we have the base class provide access functions for the \texttt{cutout\_row/col} variables (in addition to the Jacobian) \FIXME{(Erin)}. A derived class could then implement these differently, e.g. by evaluating Gary's WCS \FIXME{(Gary)}. Both this and the way shape measurement codes find the matching PSFEx model files could be implemented by an external simple table that maps exposure and CCD IDs to auxiliary filenames.


\subsection{A MEDS API for LSST}

\FIXME{Jim, Erin, Joe, Josh, Daniel: describe how this is implemented; it seems like an API that generates an object's MEDS information on the fly could be feasible}

% ----------------------------------------------------------------------

\section{PIFF: PSFs in the Full FOV}

\FIXME{write an introduction of why we need this: astrometric distortions -> WCS, coherent patterns over full FOV, Zernickes, better interpolation schemes}

\subsection{Gaussian Process Interpolation}

\FIXME{Josh, Gary, Mike, Niall, Pierre-Francois, Ami: describe}

\section{Shape measurement}

\FIXME{quick intro of lessons learned from DES Y1}

\subsection{BFD on real data}

\FIXME{Gary, Daniel, Joe, Katie, Ami: describe}

The two components missing for this are
\begin{itemize}
\item a variant of \texttt{simpleImage} (see \texttt{momentcalc.py} in the BFD repository) that can take multiple postage stamps of the same galaxies with their respective WCS registrations (in the form of the position of a centroid estimated in WCS and transformed to the postage stamp pixel system) and Jacobians, PSF models, and an estimate of the overall centroid in WCS \FIXME{(Katie)}
\item a function that can get these inputs to the new variant of \texttt{simpleImage} from a MEDS file (using the python \texttt{meds} or a derived class) \FIXME{(Daniel)}
\end{itemize}


% ----------------------------------------------------------------------

\section{An image simulation pipeline for PSF and shape measurement validation}

\FIXME{Joe, Mike, Erin, Troxel, Gary, Daniel, Niall, Ami, Katie: describe}

\subsection{Goals}
Goals: Simulation engines primarily for validation. Win some Gin from Catherine Heymans.

The subsections below describe stages of this process and the options or considerations for it.

\subsection{(Statistical) Requirements}

We need to define cosmology-driven requirements for the simulation, as these will set the simulation volume requirements and thus the computing requirements etc.. Particularly important to do this if we e.g. need to find/apply for more computing resources. 

One simple approach to setting requirements is to assume we only need to estimate a mean multiplicative bias, $\left<m_i\right>$ and additive bias, $\left<c_i\right>$ per redshift bin $i$. Then from a simulation with input shear $\gamma_{\mathrm{true}}$, 
\begin{equation}
\left<m_i\right> = \left<\frac{\gamma_{\mathrm{obs}}-\gamma_{\mathrm{true}}}{\gamma_{\mathrm{true}}}\right>,
\end{equation}
where the (possibly weighed) averaging is over all galaxies in redshift bin $i$. It follows that
\begin{equation}
\sigma_m = \frac{\sigma_e}{\gamma_{\mathrm{true}} \sqrt{N_{\mathrm{gal},i}}}
\end{equation}
i.e. for a given $\sigma_m$ one can estimate the required number of simulated galaxies per redshift bin, $N_{\mathrm{gal},i}$.
For postage-stamp style image simulations which provide effective tests of effects like noise bias, galaxy bias and PSF deconvolution, this kind of approach is probably sufficient, and can be used to set the number of postage-stamps required. We believe these types of simulation are still useful as a first test of shear estimation methods, see the \emph{tide-pool} simulation mode below.

When it comes to testing our ability to estimate unbiased shear statistics on real data, there are many more effects to consider. Even if a shape measurement method can succeed on postage-stamp style simulations selection effects, PSF modelling errors and crowding/blending will produce scale dependent biases on shear statistics. For example, excluding blended galaxies produces a bias in the small-scale cosmic shear signal (blended galaxies are more likely to be in high projected galaxy number density, high convergence regions \citep{hartlap2011,maccrann2017}). Meanwhile for tangential shear statistics such as cluster-lensing, source galaxies which are close to the lens centres are likely effected by different noise properties and worse contamination from blending.

A more complete way of setting the requirements on the image simulations is simply to aim to be able to test the recovery of any shear statistic we estimate on the the real survey data, to some fraction of the statistical uncertainty with which we can estimate that statistic on the real survey data. Assuming shot/shape-noise is the dominant source of statistical error, any shear statistic (that is reliably reproduced in the simulation) can be tested at a precision which is a fraction $f$ of the statistical error by producing $N_{\mathrm{sim}}1/f^2$ simulated copies of the real survey data. 

%I've brain-dumped a few thoughts on a couple of different (but certainly related) approaches %we could take to this, (i) how many galaxies/galaxy pairs do we need to test our desired %statistics to a given precision? (ii) How many realisations of our survey do we need test our %desired statistics to a given precision? I think the second approach is probably simpler %because a simulation of our survey will automatically (of course limited by the simulation %realism) have distributions of certain relevant survey properties (e.g. noise, PSF) that match %the real data. 
%
%We want to demonstrate that our shear estimation pipelines can recover unbiased shear-shear %and tangential shear signals to better than $X_i\%$, $Y_i\%$  for in $n_z$ redshift bins, $i$, %for $0<z<z_{\mathrm{max}}$ for some range of scales $\theta_{\mathrm{min}} < \theta < \theta_{\%mathrm{max}}$ (we could also phrase in terms of $l$ and $C_l$. This requires:
%\begin{align}
%\left<(1+m_i)(1+m_j)\right>(\theta) + \left<c_i c_j\right>(\theta)/\left<\gamma \gamma\right>(\%theta) < X\%, \\ 
%\left<n_{\mathrm{lens}}(1+m_i)\right> < Y\%.
%\end{align}
%
%Ignoring the scale dependence, assuming a constant shear, and that we calculate $m$ as
%\begin{equation}
%\left<m_i\right> = \left<\frac{\gamma_{\mathrm{obs}}-\gamma_{\mathrm{true}}}{\gamma_{\mathrm{%true}}}\right>,
%\end{equation}
%where the (possibly weighed) averaging is over all galaxies in redshift bin $i$.
%\begin{equation}
%\sigma_m = \frac{\sigma_e}{\gamma_{\mathrm{true}} \sqrt{N_{\mathrm{gal}}}}
%\end{equation}
%We want e.g. $\sigma_{m_i} < 0.5 X_i\%$, so e.g. for $X_i = 1\%$, $\gamma_{\mathrm{true}}=0.01$%, $\sigma_e = 0.2$, we'd need to simulate $1.6\times10^7$ galaxies per redshift bin.
%
%Are we worried about scale dependence? For shear-shear, we get selection biases due to %blending (blended galaxies are more likely to be in high galaxy number density, high %convergence regions \citep{hartlap2011,maccrann2017}). Spatial correlations in observing %conditions may produce spatial correlations in the shear biases. For tangential shear, %increased crowding closer to clusters/lens galaxies will produce scale dependent shear biases \%citep{melchior2015,simet2015}.
%
%An alternative way to think about the requirements is to first assume that we want to %simulated $N_{\mathrm{sim}}$ copies of our survey ($N_{\mathrm{sim}}$ could, but probably %wouldn't be less than 1). This approach has the advantage that (to the extent that the %simulated survey properties are realistic), the simulated survey properties (e.g. noise, PSF %etc.) will have the same distributions as the data. If we want to know the accuracy to which %our pipeline recovers some statistic  to better than a fraction $f$ of the shape noise errors %on that statistic we have in the real data, then we require $N_{\mathrm{sim}} = 1/f^2$ %realisations of our data. 

We envisage two main modes of the image simulations. 
\begin{enumerate}
\item \emph{Tide-pool} Fast, straight to postage-stamps simulations where different marine organisms (e.g. complex morphology, PSF model errors) are turned on and off. Galaxies written straight to MEDS files, or are generated on-the-fly. No neighbours.
\item \emph{Pacific} Full single-epoch survey images are rendered. Coadd images are produced for detection/deblending. PSF estimation is performed on the SE images. MEDS files produced using SE images and coadd information. Some shortcuts probably needed!
\end{enumerate}

Discussion points:
\begin{itemize}
\item{What should $N_{\mathrm{sim}}$ be? Note that most of the statistics we use are cosmic variance limited on large scales, so beating down the shape noise may not be so relevant. We will know the `cosmic variance' (or rather we'll know the particular realisation of the cosmological signal) in the simulation. Having said that, if they effects we are most worried about (blending etc.) are worst at small scales, then shape noise would be the dominant source of statistical uncertainty.}
\item{How can we reduce $N_{\mathrm{sim}}$? One option would be to boost the shear signal - the stronger the simulated signal, the better fractional precision can be tested. However, concerns exist about higher order shear biases, and breaking the relation between galaxy number density and shear. For postage-stamp styles simulations, presumably we can use ring-test type tricks to reduce shape noise. Is there something similar we can use for the detection simulation e.g. rotate shape noise between realisations?}
\item{What kind of shear fields should we use? If we use something realistic (e.g. from ray-tracing), how do we test that we're recovering it correctly, given that a given method will only use a subset of the galaxies?}
\end{itemize}

Several main initial tasks:
\begin{enumerate}
\item{Finish writing up this plan. Produce  (NM+)}
\item{Design simulation software framework (JZ+)}
\item{Design and implement input galaxy catalog 
$->$ galaxy appearance modules (can start v. simple, and produce multiple of these!)}
\item{Estimate timings + memory usage for simulation steps. Could split this into several tasks e.g. image rendering timing (i.e. mostly GalSim stuff) (Name?), Coadding/Detection (i.e. SWARP + SExtractor) timing (Name?).}
\item{Estimate computing requirements for various simulation modes (this should be straightforward once the previous step is completed).}
\end{enumerate}

\subsection{Required Ingredients}

\subsubsection{Input Catalogues}

Requirement: Galaxy sample with physically sensible clustering, redshift evolution, morphologies, colours, and correlations between the above. Sufficiently complex morphologies to test model bias, and sensible variation in morphology between filters. 

\begin{itemize}
\item Starting from an observed catalog is problematic: measured quantities get noisy at the faint end, we won't get sub-detection objects.
\item Proposal: Start from N-body + galaxy simulation e.g. BCC.
\item Map simulation outputs (e.g. color, size) to image properties in each filter (e.g. bulge/disc, size, amount of star formation knots). Look into Lanusse method.
\item Needs to go to high enough redshift and depth for deep fields (and for sufficient sub-detection objects in wide-field).
\end{itemize}

\subsubsection{Shear Field}

The following options, probably we'll want to do one of the first two for the Pacific simulation. Other options fine for tide-pool simulation. 
\begin{itemize}
\item From saved N-body results (see above)
\item Spatially varying but without evolution within a redshift bin
\item Spatially varying but without redshift evolution
\item Constant
\end{itemize}

\subsubsection{Survey Details}

\begin{itemize}
\item Real data pointings
\item Exposure times - from real survey
\item Noise levels - from real survey
\item Sky background - from real survey
\item Deep data - Same process but with more exposures
\end{itemize}


\subsubsection{True Astrometry}

\begin{itemize}
\item Flat WCS
\item Real image WCS
\item Gary's WCS
\item FITS header WCS
\item One of the above + some error distribution
\end{itemize}

\subsubsection{True PSF}

\begin{itemize}
\item Estimated real ones from Piff
\item Additional complexity, adding variation on smaller scales than 
\item Fixed values
\item Colour-dependence of PSF.
	  Full implementation 100 times slower.
	  Could make it a function of a single colour parameter, linearly interpolated.
	  Effective PSF from real SED? Function of (g-i).
	  Intra-band resolution of PSF.  Do this at n wavelengths.
	  Like using a chunky SED.
\end{itemize}

\subsubsection{Star Catalogue}

\begin{itemize}
\item Gaia?
\item Randomly, function of latitude.
\item SEDs - some in galsim already, need more?
\end{itemize}

\subsubsection{Artifacts}
\begin{itemize}
\item Tape bumps
\item CTI
\item Brighter-fatter
\item Non-linearity
\item Non-convolutional things
\item Image artifacts
\end{itemize}

\subsubsection{Masking}

\begin{itemize}
\item Real
\item Real + artifacts
\end{itemize}

\subsubsection{Single-epoch Rendering}

\begin{itemize}
\item GalSim
\end{itemize}

\subsubsection{Coadding}
\begin{itemize}
\item Run full pipeline - i.e. run swarp
\item Shortcut option: draw coadd directly. What does this miss? What is required to test this?
\end{itemize}

\subsubsection{Detection \& Segmenting}
\begin{itemize}
\item Needed for lists of detected objects and segmentation masks
\item Run full pipeline - SExtractor on coadd
\item Generate object list and seg map from truth catalogs
\end{itemize}

\subsubsection{Estimated PSF}
\begin{itemize}
\item Find starting stars - on coadd using SExtractor? Can we do this without spread-model?
\item Run PIFF
\item Use truth
\end{itemize}

\subsubsection{Estimated astrometry}
\begin{itemize}
\item Cannot re-do the actual astrometry process
\item Use the original FITS ones
\item Use truth + some error term
\end{itemize}

\subsubsection{Photometric Calibration}
\begin{itemize}
\item Could place a small error on the truth - scale objects by some factor.
\end{itemize}

\subsubsection{MEDS}
\begin{itemize}
\item Make a MEDS file and run on it!
\end{itemize}



\section{\Mcal\ Response for Stars}

Testing to see if we can cause positive responses for stars in a simulation.
In some scenarios we see $<R> \sim 0.25$ in real data.

\subsection{Variations in PSF}

Consider the case where the PSF model used is accurate in the mean but 
for an individual galaxy the truth varies significantly.  The response
for stars at high \snr ($> 100$), and using forward modeling, is shown in
figure \ref{fig:Rstarfm}.  The same for adaptive moments, without
PSF correction. The response has mean about 0.1 for forward modeling,
but nearly zero for adaptive moments.  In both cases the distribution
is nearly gaussian, whereas in real data it tends to be highly asymmetric,
with mode at $R \sim 0.5$.


\begin{figure}[p]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/test_psf_var-000-R11.pdf}

    \caption{Response for high \snr\ stars when varying the PSF from
    object to object, but using
    the mean model when performing \mcal\ operatioins, using the forward modeling estimator.
    Parameters of the best fit gaussian are shown. }

	\label{fig:Rstarfm}

\end{figure}
\begin{figure}[p]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/test_psf_var-000-R11-admom.pdf}

    \caption{Same as figure \ref{fig:Rstarfm}, but adaptive moments estimator with no PSF correction}

	\label{fig:Rstaram}

\end{figure}



% ----------------------------------------------------------------------

\subsection*{Acknowledgments}

We acknowledge financial and organizational support for our workshop from LSSTC and KIPAC and the hospitality of Hostelling International.

\input{acknowledgments}

%{\it Facilities:} \facility{LSST}

% Include both collaboration papers and external citations:
\bibliography{lsstdesc,main}

\end{document}
% ======================================================================
% 
